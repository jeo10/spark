{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, Row\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/01 16:54:27 WARN Utils: Your hostname, debian resolves to a loopback address: 127.0.1.1; using 192.168.100.4 instead (on interface eno2)\n",
      "22/10/01 16:54:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/jeo/anaconda3/envs/data/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/10/01 16:54:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkContext(master='local', appName='DataFrames')\n",
    "sqlContext = SQLContext(spark)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path_file = '/home/jeo/Documents/platzi/curso_de_fundamentos_de_spark_para_big_data/curso-apache-spark-platzi-master/files/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def eliminar_encabezado(indice, iterador):\n",
    "    return iter(list(iterador)[1:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "deportistaError = spark.textFile(path_file + 'deportistaError.csv') \\\n",
    "    .map(lambda l: l.split(','))\n",
    "\n",
    "deportistaError = deportistaError.mapPartitionsWithIndex(eliminar_encabezado)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n ['2', 'A Lamusi', '1', '23', '170', '60', '199']]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deportistaError.take(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|            1|           A Dijiang|     1|  24|   180|  80|      199|\n",
      "|            2|            A Lamusi|     1|  23|   170|  60|      199|\n",
      "|            3| Gunnar Nielsen Aaby|     1|  24|      |    |      273|\n",
      "|            4|Edgar Lindenau Aabye|     1|  34|      |    |      278|\n",
      "|            5|Christine Jacoba ...|     2|  21|   185|  82|      705|\n",
      "|            6|     Per Knut Aaland|     1|  31|   188|  75|     1096|\n",
      "|            7|        John Aalberg|     1|  31|   183|  72|     1096|\n",
      "|            8|\"Cornelia \"\"Cor\"\"...|     2|  18|   168|    |      705|\n",
      "|            9|    Antti Sami Aalto|     1|  26|   186|  96|      350|\n",
      "|           10|\"Einar Ferdinand ...|     1|  26|      |    |      350|\n",
      "|           11|  Jorma Ilmari Aalto|     1|  22|   182|76.5|      350|\n",
      "|           12|   Jyri Tapani Aalto|     1|  31|   172|  70|      350|\n",
      "|           13|  Minna Maarit Aalto|     2|  30|   159|55.5|      350|\n",
      "|           14|Pirjo Hannele Aal...|     2|  32|   171|  65|      350|\n",
      "|           15|Arvo Ossian Aaltonen|     1|  22|      |    |      350|\n",
      "|           16|Juhamatti Tapio A...|     1|  28|   184|  85|      350|\n",
      "|           17|Paavo Johannes Aa...|     1|  28|   175|  64|      350|\n",
      "|           18|Timo Antero Aaltonen|     1|  31|   189| 130|      350|\n",
      "|           19|Win Valdemar Aalt...|     1|  54|      |    |      350|\n",
      "|           20|  Kjetil Andr Aamodt|     1|  20|   176|  85|      742|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaError = deportistaError.map(lambda l : (l[0], l[1], l[2], l[3], l[4], l[5], l[6]))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('deportista_id', StringType(), False),\n",
    "    StructField('nombre', StringType(), False),\n",
    "    StructField('genero', StringType(), False),\n",
    "    StructField('edad', StringType(), False),\n",
    "    StructField('altura', StringType(), False),\n",
    "    StructField('peso', StringType(), False),\n",
    "    StructField('equipo_id', StringType(), False)\n",
    "])\n",
    "\n",
    "deportistaErrorDF = sqlContext.createDataFrame(deportistaError, schema)\n",
    "deportistaErrorDF.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<function __main__.<lambda>(z)>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conversionEnteros(valor):\n",
    "    return int(valor) if len(valor) > 0 else None\n",
    "\n",
    "conversionEnteros_udf = udf(lambda z: conversionEnteros(z), IntegerType())\n",
    "sqlContext.udf.register('conversionEnteros_udf', conversionEnteros_udf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|AlturaUDF|\n",
      "+---------+\n",
      "|      180|\n",
      "|      170|\n",
      "|     null|\n",
      "|     null|\n",
      "|      185|\n",
      "|      188|\n",
      "|      183|\n",
      "|      168|\n",
      "|      186|\n",
      "|     null|\n",
      "|      182|\n",
      "|      172|\n",
      "|      159|\n",
      "|      171|\n",
      "|     null|\n",
      "|      184|\n",
      "|      175|\n",
      "|      189|\n",
      "|     null|\n",
      "|      176|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaErrorDF.select(conversionEnteros_udf('altura').alias('AlturaUDF')).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}