{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, Row\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/01 16:40:25 WARN Utils: Your hostname, debian resolves to a loopback address: 127.0.1.1; using 192.168.100.4 instead (on interface eno2)\n",
      "22/10/01 16:40:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/jeo/anaconda3/envs/data/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/10/01 16:40:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkContext(master='local', appName='DataFrames')\n",
    "sqlContext = SQLContext(spark)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path_file = '/home/jeo/Documents/platzi/curso_de_fundamentos_de_spark_para_big_data/curso-apache-spark-platzi-master/files/'\n",
    "def eliminar_encabezado(indice, iterador):\n",
    "    return iter(list(iterador)[1:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|            1|           A Dijiang|     1|  24|   180|80.0|      199|\n",
      "|            2|            A Lamusi|     1|  23|   170|60.0|      199|\n",
      "|            3| Gunnar Nielsen Aaby|     1|  24|     0| 0.0|      273|\n",
      "|            4|Edgar Lindenau Aabye|     1|  34|     0| 0.0|      278|\n",
      "|            5|Christine Jacoba ...|     2|  21|   185|82.0|      705|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoRDD = spark.textFile(path_file+'deportista.csv') \\\n",
    "                        .map(lambda l: l.split(\",\"))\n",
    "deportistaOlimpicoRDD2 = spark.textFile(path_file+'deportista2.csv') \\\n",
    "                        .map(lambda l: l.split(\",\"))\n",
    "\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.union(deportistaOlimpicoRDD2)\n",
    "\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.mapPartitionsWithIndex(eliminar_encabezado)\n",
    "\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.map(lambda l: (\n",
    "    int(l[0]),\n",
    "    str(l[1]),\n",
    "    int(l[2]),\n",
    "    int(l[3]),\n",
    "    int(l[4]),\n",
    "    float(l[5]),\n",
    "    int(l[6])\n",
    "))\n",
    "\n",
    "deportista_schema = StructType([\n",
    "    StructField('deportista_id', IntegerType(), False),\n",
    "    StructField('nombre', StringType(), False),\n",
    "    StructField('genero', IntegerType(), False),\n",
    "    StructField('edad', IntegerType(), False),\n",
    "    StructField('altura', IntegerType(), False),\n",
    "    StructField('peso', FloatType(), False),\n",
    "    StructField('equipo_id', IntegerType(), False)\n",
    "])\n",
    "\n",
    "deportistaDF = sqlContext.createDataFrame(deportistaOlimpicoRDD, deportista_schema)\n",
    "deportistaDF.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-------------+--------+---------+\n",
      "|resultado_id|medalla|deportista_id|juego_id|evento_id|\n",
      "+------------+-------+-------------+--------+---------+\n",
      "|           1|     NA|            1|      39|        1|\n",
      "|           2|     NA|            2|      49|        2|\n",
      "|           3|     NA|            3|       7|        3|\n",
      "|           4|   Gold|            4|       2|        4|\n",
      "|           5|     NA|            5|      36|        5|\n",
      "+------------+-------+-------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultadoSchemaRDD = StructType([\n",
    "    StructField('resultado_id', IntegerType(), False),\n",
    "    StructField('medalla', StringType(), False),\n",
    "    StructField('deportista_id', IntegerType(), False),\n",
    "    StructField('juego_id', IntegerType(), False),\n",
    "    StructField('evento_id', IntegerType(), False)\n",
    "])\n",
    "resultadoDF = sqlContext.read.schema(resultadoSchemaRDD).option('header', 'True').csv(path_file + 'resultados.csv')\n",
    "resultadoDF.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+\n",
      "|id_equipo|              equipo|sigla|\n",
      "+---------+--------------------+-----+\n",
      "|        1|         30. Februar|  AUT|\n",
      "|        2|A North American ...|  MEX|\n",
      "|        3|           Acipactli|  MEX|\n",
      "|        4|             Acturus|  ARG|\n",
      "|        5|         Afghanistan|  AFG|\n",
      "+---------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/01 16:40:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: id, equipo, sigla\n",
      " Schema: id_equipo, equipo, sigla\n",
      "Expected: id_equipo but found: id\n",
      "CSV file: file:///home/jeo/Documents/platzi/curso_de_fundamentos_de_spark_para_big_data/curso-apache-spark-platzi-master/files/paises.csv\n"
     ]
    }
   ],
   "source": [
    "paises_schema = StructType([\n",
    "    StructField('id_equipo', IntegerType(), False),\n",
    "    StructField('equipo', StringType(), False),\n",
    "    StructField('sigla', StringType(), False)\n",
    "])\n",
    "paisesDF = sqlContext.read.schema(paises_schema).option('header', 'True').csv(path_file + 'paises.csv')\n",
    "paisesDF.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "resultadoDF.registerTempTable('resultado')\n",
    "deportistaDF.registerTempTable('deportista')\n",
    "paisesDF.registerTempTable('paises')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|            1|           A Dijiang|     1|  24|   180|80.0|      199|\n",
      "|            2|            A Lamusi|     1|  23|   170|60.0|      199|\n",
      "|            3| Gunnar Nielsen Aaby|     1|  24|     0| 0.0|      273|\n",
      "|            4|Edgar Lindenau Aabye|     1|  34|     0| 0.0|      278|\n",
      "|            5|Christine Jacoba ...|     2|  21|   185|82.0|      705|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM deportista\").show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/01 16:43:35 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: id, equipo, sigla\n",
      " Schema: id_equipo, equipo, sigla\n",
      "Expected: id_equipo but found: id\n",
      "CSV file: file:///home/jeo/Documents/platzi/curso_de_fundamentos_de_spark_para_big_data/curso-apache-spark-platzi-master/files/paises.csv\n",
      "[Stage 6:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+\n",
      "|medalla|  equipo|sigla|\n",
      "+-------+--------+-----+\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "| Bronze|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "+-------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    SELECT medalla, equipo, sigla FROM resultado r\n",
    "    JOIN deportista d\n",
    "    ON r.deportista_id = d.deportista_id\n",
    "    JOIN paises p\n",
    "    ON p.id_equipo = d.equipo_id\n",
    "    WHERE medalla <> 'NA'\n",
    "    ORDER BY sigla DESC\n",
    "\"\"\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<SparkContext master=local appName=DataFrames>",
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://192.168.100.4:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local</code></dd>\n              <dt>AppName</dt>\n                <dd><code>DataFrames</code></dd>\n            </dl>\n        </div>\n        "
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}